# ğŸ”’ SECURITY AUDIT REPORT
## Decentralized Storage System - Senior Security Engineer Review

**Date:** February 10, 2026  
**Auditor Role:** Senior Security Engineer  
**System Version:** 1.0.0  
**Files Audited:** `decentralized_storage_engine.py`, `orchestrator.py`, `main.py`

---

## ğŸ“‹ EXECUTIVE SUMMARY

**Overall Security Posture:** âš ï¸ **MODERATE RISK**

The system demonstrates strong cryptographic foundations with proper encryption-before-sharding and tamper detection. However, **CRITICAL vulnerabilities** in metadata security and concurrency handling pose immediate risks to confidentiality and data consistency.

**Critical Issues Found:** 2  
**High-Risk Issues:** 1  
**Medium-Risk Issues:** 2  
**Recommendations:** 5

---

## ğŸ” DETAILED FINDINGS

### 1ï¸âƒ£ Zero-Knowledge Check: Encryption Before Sharding

**Status:** âœ… **PASS** - No Data Leakage

**Analysis:**
```python
# decentralized_storage_engine.py, lines 76-89
def encrypt_and_shard(self, plaintext: bytes):
    # Step 1: Client-side encryption FIRST
    encrypted_data = self.cipher.encrypt(plaintext)  # Line 78
    
    # Step 2: THEN sharding (on encrypted data)
    encoder = zfec.Encoder(self.k_required, self.m_total)
    shards = encoder.encode(chunks)  # Line 89
```

**Findings:**
- âœ… Encryption occurs at **line 78** using Fernet (AES-128-CBC + HMAC-SHA256)
- âœ… Sharding occurs at **line 89** on **already encrypted data**
- âœ… Storage nodes (orchestrator.py line 201) receive `shard_data` which is encrypted
- âœ… No raw plaintext ever leaves the encryption boundary

**Verdict:** Storage nodes operate in **true zero-knowledge mode**. They cannot decrypt shard contents.

---

### 2ï¸âƒ£ Erasure Coding Integrity: Reed-Solomon Implementation

**Status:** âœ… **PASS** - Correctly Configured

**Analysis:**
```python
# decentralized_storage_engine.py, lines 27-28
self.k_required = 3  # Minimum shards needed
self.m_total = 5     # Total shards created
```

**Reed-Solomon Configuration Verification:**
- âœ… k=3, m=5 correctly set (verified in lines 27-28)
- âœ… Any 3 of 5 shards can reconstruct data
- âœ… System tolerates 2 node failures (m - k = 2)

**Download Error Handling:**
```python
# orchestrator.py, lines 290-310
downloaded_shards = await asyncio.gather(*download_tasks)

# Filter successful downloads
for shard_id, shard_data in zip(shard_ids, downloaded_shards):
    if shard_data is not None:  # Handles 404 / errors gracefully
        successful_shards.append(shard_data)

# Verify threshold
if len(successful_shards) < metadata['k_required']:
    raise ValueError(f"Insufficient shards: {len} available, {k} required")
```

**Findings:**
- âœ… `_download_shard_from_node` (line 121) returns `None` on failure (404 or exception)
- âœ… Line 299 filters out failed downloads with `if shard_data is not None`
- âœ… Line 308 enforces strict threshold check before reconstruction
- âœ… System properly handles 2 simultaneous node failures

**Verdict:** Availability guarantee is mathematically sound and properly implemented.

---

### 3ï¸âƒ£ Tamper-Proofing: SHA-256 Hash Verification

**Status:** âš ï¸ **PARTIAL PASS** - Weakness in Enforcement

**Analysis:**

**Hash Generation (CORRECT):**
```python
# decentralized_storage_engine.py, lines 98-102
for shard_id, shard in enumerate(shards):
    shard_hash = self._calculate_hash(shard)  # SHA-256
    metadata[shard_id] = shard_hash
```

**Hash Verification (CORRECT but OPTIONAL):**
```python
# decentralized_storage_engine.py, lines 150-172
def recover_and_decrypt(self, shards, shard_ids, metadata, 
                       verify_integrity: bool = True):  # âš ï¸ OPTIONAL!
    
    if verify_integrity:
        for shard_id, shard in zip(shard_ids, shards):
            actual_hash = self._calculate_hash(shard)
            if actual_hash != expected_hash:
                raise ValueError("Tampering detected!")  # âœ… Strict check
    else:
        print("[WARNING] Integrity verification DISABLED")  # âš ï¸ Allows bypass
```

**Findings:**
- âœ… SHA-256 hash calculated for EACH shard before storage (line 100)
- âœ… Strict comparison during retrieval (line 165: `actual_hash != expected_hash`)
- âœ… Reconstruction aborts immediately on mismatch (line 167: `raise ValueError`)
- âš ï¸ **WEAKNESS:** `verify_integrity` parameter allows disabling checks (line 150)
- âš ï¸ Orchestrator (line 322) calls with `verify_integrity=True` but this could be changed

**Vulnerability:**
While the orchestrator currently enforces integrity checks, the API design allows bypassing this critical security feature. A future code change or misconfiguration could disable tamper detection.

**Verdict:** Integrity mechanism is **cryptographically sound** but **enforcement is not mandatory**.

---

### 4ï¸âƒ£ Metadata Security: Encryption Key Exposure

**Status:** ğŸš¨ **CRITICAL VULNERABILITY** - Plaintext Key Leakage

**Analysis:**

**Metadata Storage (INSECURE):**
```json
// metadata/test_upload.metadata.json
{
  "filename": "test_upload.txt",
  "encryption_key": "ra0vMt_JUZRjC-R7yWaTsXn15g7zxNbBAorMUENjijY=",  // âš ï¸ PLAINTEXT!
  "shard_metadata": { ... }
}
```

**File System Exposure:**
- ğŸš¨ Encryption keys stored in **plaintext** in `.metadata.json` files
- ğŸš¨ Line 223 in orchestrator.py: `"encryption_key": self.storage_engine.encryption_key.decode()`
- ğŸš¨ Anyone with file system access can read all keys immediately

**API Exposure Analysis:**

**Endpoint 1: `/metadata/{filename}` (SECURE)**
```python
# main.py, lines 352-356
safe_metadata = metadata.copy()
safe_metadata["encryption_key"] = "[REDACTED]"  # âœ… Properly redacted
```

**Endpoint 2: `/files` (ğŸš¨ CRITICAL VULNERABILITY)**
```python
# main.py, lines 163-176
with open(metadata_file, "r") as f:
    metadata = json.load(f)

files_list.append({
    "filename": metadata["filename"],
    "file_hash": metadata["file_hash"][:16] + "...",
    # ... but NO redaction of encryption_key in source metadata!
})
```

**CRITICAL FINDING:**
While `/metadata/{filename}` redacts keys, the **`/files` endpoint exposes full metadata objects**. An attacker can:

1. Call `GET /files` to list all files
2. Extract `metadata_file` name from response
3. Read metadata JSON directly (if file system accessible) **OR**
4. The metadata object is loaded but the encryption key is NOT explicitly excluded

**Proof of Concept Attack:**
```bash
# Attacker's perspective
curl http://localhost:8000/files
# Response includes metadata_file: "test_upload.metadata.json"

# If attacker has filesystem access:
cat metadata/test_upload.metadata.json
# Gets encryption key: "ra0vMt_JUZRjC-R7yWaTsXn15g7zxNbBAorMUENjijY="

# Attacker can now:
# 1. Download shards from nodes (already encrypted)
# 2. Use stolen key to decrypt without needing the gateway
```

**Impact Assessment:**
- **Confidentiality:** âŒ COMPROMISED - Keys accessible to anyone with file read access
- **Zero-Knowledge:** âŒ BROKEN - Gateway holds decryption keys for all files
- **Defense in Depth:** âŒ ABSENT - No key encryption, no access controls

**Verdict:** This is a **CRITICAL security flaw** that completely undermines encryption.

---

### 5ï¸âƒ£ Concurrency Safety: Race Conditions in Upload Flow

**Status:** âš ï¸ **HIGH RISK** - Race Condition Detected

**Analysis:**

**Upload Flow in orchestrator.py:**
```python
# Lines 203-238
# Step 1: Upload shards concurrently
upload_results = await asyncio.gather(*upload_tasks)  # Line 209

# Step 2: Verify uploads
failed_uploads = sum(1 for result in upload_results if not result)
if failed_uploads > 0:
    raise ValueError(f"{failed_uploads} shard uploads failed")  # Line 216

# Step 3: Create metadata
metadata_manifest = { ... }  # Line 219

# Step 4: Save metadata to disk
with open(metadata_path, "w") as f:
    json.dump(metadata_manifest, f, indent=2)  # Line 236
```

**Race Condition Scenarios:**

**Scenario A: Crash After Upload, Before Metadata Save**
```
Time T1: Shards uploaded successfully to nodes (line 209) âœ…
Time T2: Upload verification passes (line 214) âœ…
Time T3: ğŸ’¥ PROCESS CRASHES (before line 236)
Time T4: Metadata never saved âŒ

Result: 
- Shards exist on storage nodes (orphaned data)
- No metadata file â†’ File cannot be retrieved
- Storage space wasted, data effectively lost
```

**Scenario B: Metadata Save Failure**
```python
# What if this fails?
with open(metadata_path, "w") as f:  # Disk full? Permission denied?
    json.dump(metadata_manifest, f, indent=2)

# No error handling! Exception propagates but shards already uploaded.
```

**Scenario C: Concurrent Uploads of Same File**
```python
# Two clients upload "document.pdf" simultaneously
Client A: Uploads shards 0-4 to nodes
Client B: Uploads shards 0-4 to nodes (overwrites Client A's shards!)

# metadata_path = "document.metadata.json"
Client A: Saves metadata (line 236)
Client B: Saves metadata (overwrites Client A's metadata!)

# Result: Metadata points to Client B's shards, Client A's upload is lost
```

**Missing Safeguards:**
- âŒ No transaction mechanism (shards + metadata as atomic unit)
- âŒ No rollback if metadata save fails after shard upload
- âŒ No file locking to prevent concurrent uploads of same file
- âŒ No cleanup of orphaned shards

**Potential Data Loss:**
If the gateway crashes after line 216 but before line 236, shards are uploaded but unrecoverable. With 100 uploads/day and 0.1% crash rate, this could result in **1 lost file every 10 days**.

**Verdict:** **High-risk race condition** with no rollback mechanism. Violates ACID properties.

---

## ğŸ¯ SECURITY PROPERTIES ASSESSMENT

### Confidentiality
**Status:** âš ï¸ **PARTIALLY ACHIEVED**

âœ… **Strengths:**
- AES-128 encryption before sharding
- Storage nodes cannot decrypt data
- Fernet provides authenticated encryption

ğŸš¨ **Weaknesses:**
- Encryption keys stored in plaintext on filesystem
- Keys accessible via metadata file enumeration
- No key rotation mechanism
- No encryption-at-rest for metadata

### Availability
**Status:** âœ… **FULLY ACHIEVED**

âœ… **Strengths:**
- Reed-Solomon (3,5) encoding provides 40% fault tolerance
- Tolerates 2 simultaneous node failures
- Graceful degradation with partial shard availability
- Async operations for performance

âš ï¸ **Weaknesses:**
- Race conditions can create unrecoverable data (orphaned shards)
- No automatic shard rebalancing after node recovery

### Integrity
**Status:** âœ… **MOSTLY ACHIEVED**

âœ… **Strengths:**
- SHA-256 hashing for each shard
- Strict hash verification before reconstruction
- File-level hash verification after recovery
- Tampering detection aborts operations

âš ï¸ **Weaknesses:**
- Integrity verification can be disabled (API design flaw)
- No protection against metadata tampering (unsigned metadata)

---

## ğŸ”§ RECOMMENDATIONS

### ğŸš¨ CRITICAL (Address Immediately)

#### **1. Encrypt Metadata Files**
```python
# Add to orchestrator.py
class MetadataEncryption:
    def __init__(self, master_key: bytes):
        self.cipher = Fernet(master_key)
    
    def save_metadata(self, metadata: dict, path: Path):
        # Encrypt entire metadata before saving
        plaintext = json.dumps(metadata).encode()
        encrypted = self.cipher.encrypt(plaintext)
        with open(path, 'wb') as f:
            f.write(encrypted)
    
    def load_metadata(self, path: Path) -> dict:
        with open(path, 'rb') as f:
            encrypted = f.read()
        plaintext = self.cipher.decrypt(encrypted)
        return json.loads(plaintext)

# Store master key in environment variable or HSM
MASTER_KEY = os.environ.get('METADATA_MASTER_KEY')
```

**Impact:** Prevents plaintext key exposure in filesystem.

#### **2. Remove Metadata from `/files` Response**
```python
# main.py, lines 163-176
files_list.append({
    "filename": metadata["filename"],
    "file_hash": metadata["file_hash"][:16] + "...",
    "size": metadata["file_size"],
    "upload_date": upload_date.isoformat(),
    "metadata_file": metadata_file.name,
    # REMOVE: Don't include actual metadata
    # ADD: Just include safe summary
    "shards_total": metadata["m_total"],
    "shards_required": metadata["k_required"],
    # DON'T expose: encryption_key, shard_metadata with hashes
})
```

#### **3. Implement Atomic Upload with Rollback**
```python
# orchestrator.py
async def upload_file_atomic(self, file_path: str) -> str:
    shard_identifiers = []
    
    try:
        # Phase 1: Upload shards
        shards, metadata = self.storage_engine.encrypt_and_shard(file_data)
        upload_results = await asyncio.gather(*upload_tasks)
        
        if any(not result for result in upload_results):
            raise UploadFailedException("Partial upload failure")
        
        # Phase 2: Save metadata (with error handling)
        try:
            metadata_path = self._save_metadata_safely(metadata_manifest)
        except Exception as e:
            # ROLLBACK: Delete uploaded shards
            await self._cleanup_shards(shard_identifiers)
            raise MetadataSaveException(f"Rollback initiated: {e}")
        
        return metadata_path
        
    except Exception as e:
        # Ensure cleanup on any failure
        await self._cleanup_shards(shard_identifiers)
        raise

async def _cleanup_shards(self, shard_identifiers: List[str]):
    """Delete shards from nodes (rollback)"""
    for node_url, shard_id in zip(self.node_urls, shard_identifiers):
        try:
            async with httpx.AsyncClient() as client:
                await client.delete(f"{node_url}/delete/{shard_id}")
        except Exception as e:
            logging.error(f"Failed to cleanup shard {shard_id}: {e}")
```

### âš ï¸ HIGH PRIORITY

#### **4. Make Integrity Verification Mandatory**
```python
# decentralized_storage_engine.py, line 150
def recover_and_decrypt(self, 
                       shards: List[bytes], 
                       shard_ids: List[int],
                       metadata: Dict[int, str]):
                       # REMOVE: verify_integrity parameter entirely
    """
    Integrity verification is now MANDATORY and cannot be disabled.
    """
    # Always verify - no bypass option
    self._verify_shard_integrity(shards, shard_ids, metadata)
    # ... rest of logic
```

#### **5. Add File Upload Locking**
```python
# orchestrator.py
import asyncio

class StorageOrchestrator:
    def __init__(self, ...):
        self._upload_locks = {}  # filename -> asyncio.Lock
    
    async def upload_file(self, file_path: str) -> str:
        filename = Path(file_path).name
        
        # Acquire lock for this filename
        if filename not in self._upload_locks:
            self._upload_locks[filename] = asyncio.Lock()
        
        async with self._upload_locks[filename]:
            # Prevent concurrent uploads of same file
            return await self._upload_file_internal(file_path)
```

---

## ğŸ“Š COMPLIANCE ASSESSMENT

| Security Principle | Status | CIA Triad |
|-------------------|--------|-----------|
| Encryption-before-sharding | âœ… Pass | **C**onfidentiality |
| Zero-knowledge storage | âœ… Pass | **C**onfidentiality |
| Erasure coding (3,5) | âœ… Pass | **A**vailability |
| Fault tolerance (2 nodes) | âœ… Pass | **A**vailability |
| SHA-256 tamper detection | âœ… Pass | **I**ntegrity |
| Hash verification enforcement | âš ï¸ Weak | **I**ntegrity |
| Metadata key protection | ğŸš¨ Fail | **C**onfidentiality |
| Atomic operations | ğŸš¨ Fail | **I**ntegrity |
| Concurrency control | âš ï¸ Weak | **I**ntegrity |

---

## ğŸ CONCLUSION

**Does the system achieve CIA as described?**

- **Confidentiality:** âš ï¸ **Partial** - Encryption works, but key management is critically flawed
- **Availability:** âœ… **Yes** - Erasure coding provides robust fault tolerance  
- **Integrity:** âœ… **Yes** - SHA-256 verification detects tampering effectively

**Overall Grade: C+** (Would be A- if metadata security and transactions were fixed)

The core cryptographic architecture is **sound and well-designed**. However, operational security weaknesses in metadata handling and transaction management create **critical attack vectors** that must be addressed before production deployment.

---

## ğŸ“… REMEDIATION TIMELINE

| Priority | Issue | Est. Effort | Deadline |
|----------|-------|-------------|----------|
| ğŸš¨ Critical | Encrypt metadata files | 4-6 hours | **24 hours** |
| ğŸš¨ Critical | Sanitize /files endpoint | 1 hour | **24 hours** |
| ğŸš¨ Critical | Atomic upload + rollback | 8-12 hours | **48 hours** |
| âš ï¸ High | Mandatory integrity checks | 2 hours | **72 hours** |
| âš ï¸ High | File upload locking | 3 hours | **72 hours** |

---

**Audit Completed By:** Senior Security Engineer  
**Next Review:** After critical fixes implemented  
**Report Classification:** Internal - Engineering Team

---

